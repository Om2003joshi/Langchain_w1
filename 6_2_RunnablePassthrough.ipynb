{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59b061de",
   "metadata": {},
   "source": [
    "### so here in the output  there is mistake in promt templrete please understsand that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50627a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import  ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables import Runnable,RunnableParallel,RunnableSequence,RunnablePassthrough\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a740af2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",                   # correct parameter\n",
    "    google_api_key=os.environ[\"GOOGLE_API_KEY\"],  # correct parameter\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Send a message\n",
    "response = llm.invoke(\"Hi\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "249e33d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=PromptTemplate(\n",
    "    template=\"write a joke about {topic}\",\n",
    "    input_variables=['topic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de1b3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2=PromptTemplate(\n",
    "    template=\"explain the following - {text}\",\n",
    "    input_variables=['text']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a51d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347ea729",
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_gen_chain=RunnableSequence(p1, llm , p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a43875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ru=RunnablePassthrough()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "115ad95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain=RunnableParallel({\n",
    "    \"joke\": RunnablePassthrough(),\n",
    "    \"explanation\":RunnableSequence(p2, llm , parser)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9547f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain=RunnableSequence(joke_gen_chain, parallel_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a8e166c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': StringPromptValue(text=\"explain the following - content='Why did the AI get a bad review at the comedy club?\\\\n\\\\nBecause it kept explaining the algorithms behind every punchline.' additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019c41a1-9f9b-7c12-a839-a09681189ef6-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 6, 'output_tokens': 1604, 'total_tokens': 1610, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1579}}\"), 'explanation': 'This is a classic joke that plays on the inherent nature of Artificial Intelligence and the dynamics of human humor.\\n\\nHere\\'s the breakdown:\\n\\n1.  **The Setup:** \"Why did the AI get a bad review at the comedy club?\"\\n    *   This sets up a scenario where an AI is attempting a human activity (stand-up comedy) in a human environment (a comedy club).\\n    *   A \"bad review\" implies it failed to perform its intended function: making people laugh.\\n\\n2.  **The Punchline:** \"Because it kept explaining the algorithms behind every punchline.\"\\n\\n3.  **The Humor (and why it\\'s funny):**\\n    *   **AI\\'s Nature:** AI is designed for logic, analysis, data processing, and understanding patterns. It operates based on algorithms. If an AI were to \"understand\" a joke, it would likely break it down into its logical components, the setup, the misdirection, the unexpected twist, and the underlying cognitive processes that make it funny.\\n    *   **Comedy\\'s Nature:** The essence of a good joke lies in surprise, misdirection, clever wordplay, and the sudden \"aha!\" moment of understanding the twist. It\\'s an experience, not a lecture.\\n    *   **The Conflict:** Explaining a joke *kills* the humor. When someone tells a joke, the audience enjoys the spontaneous realization of the punchline. If you then dissect it, explain *why* it\\'s funny, or reveal the \"mechanics\" behind it, the magic is gone. The AI, in its literal and analytical approach, would be doing exactly what ruins a joke for a human audience. It\\'s trying to be helpful by providing context, but in doing so, it destroys the very thing it\\'s supposed to be delivering (laughter).\\n    *   **Irony:** The AI is performing its function (explaining complex processes, like algorithms) perfectly, but in the context of a comedy club, this perfect execution leads to a complete failure of its *new* function (being funny).\\n\\nIn essence, the joke highlights the difference between human intuition and AI\\'s logical processing, especially when it comes to nuanced human concepts like humor. The AI is too literal and analytical for the spontaneous, often illogical, joy of a good laugh.'}\n"
     ]
    }
   ],
   "source": [
    "print(final_chain.invoke({\"topic\":\"ai\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8323237f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': StringPromptValue(text='explain the following - content=\"Here are a few:\\\\n\\\\n1.  Why did the cricket fan bring a sleeping bag to the match?\\\\n    Because he heard it was a **Test** match!\\\\n\\\\n2.  Why did the cricket player bring a piece of string to the game?\\\\n    In case he needed to **tie** the match!\\\\n\\\\n3.  What\\'s a cricket player\\'s favorite type of music?\\\\n    Anything with a good **wicket** beat!\" additional_kwargs={} response_metadata={\\'finish_reason\\': \\'STOP\\', \\'model_name\\': \\'gemini-2.5-flash\\', \\'safety_ratings\\': [], \\'model_provider\\': \\'google_genai\\'} id=\\'lc_run--019c41a8-9781-7661-ac0b-d8393bc63003-0\\' tool_calls=[] invalid_tool_calls=[] usage_metadata={\\'input_tokens\\': 6, \\'output_tokens\\': 1393, \\'total_tokens\\': 1399, \\'input_token_details\\': {\\'cache_read\\': 0}, \\'output_token_details\\': {\\'reasoning\\': 1299}}'), 'explanation': 'The text you provided is a structured output, likely from an API call to an AI model (specifically, a Google Gemini model). It contains the actual content generated by the model, along with various metadata about the generation process.\\n\\nLet\\'s break down each part:\\n\\n1.  **`text=\\'...\\'`**: This is the main string containing the entire output.\\n\\n2.  **`content=\"Here are a few:\\\\\\\\n\\\\\\\\n1. Why did the cricket fan bring a sleeping bag to the match?\\\\\\\\n Because he heard it was a **Test** match!\\\\\\\\n\\\\\\\\n2. Why did the cricket player bring a piece of string to the game?\\\\\\\\n In case he needed to **tie** the match!\\\\\\\\n\\\\\\\\n3. What\\'s a cricket player\\'s favorite type of music?\\\\\\\\n Anything with a good **wicket** beat!\"`**:\\n    *   This is the **actual response** generated by the AI model.\\n    *   It\\'s a list of three cricket-themed jokes.\\n    *   The `\\\\n` characters represent newlines, formatting the jokes for readability.\\n    *   The `**...**` indicates bold text, highlighting the pun in each joke.\\n    *   **Explanation of the Jokes:**\\n        *   **Joke 1 (Test match):** \"Test match\" is a long form of cricket, often lasting several days. The pun plays on the word \"Test\" sounding like a school test or an endurance test, implying one might need to sleep during it.\\n        *   **Joke 2 (tie the match):** In cricket (and other sports), to \"tie the match\" means the scores are equal at the end. The pun uses the literal meaning of \"tie\" (with a piece of string).\\n        *   **Joke 3 (wicket beat):** A \"wicket\" is one of the three stumps in cricket, and also refers to a successful dismissal of a batsman. \"Wicked\" is slang for excellent or cool. The pun combines \"wicket\" with \"beat\" (rhythm in music) to sound like \"wicked beat.\"\\n\\n3.  **`additional_kwargs={}`**:\\n    *   This is an empty dictionary for any extra, non-standard parameters that might be passed during the API call. In this case, none were used.\\n\\n4.  **`response_metadata={...}`**:\\n    *   This dictionary contains information about the model\\'s response itself.\\n    *   **`\\'finish_reason\\': \\'STOP\\'`**: The model completed its response naturally, reaching a logical end point rather than being cut off due to length limits or other issues.\\n    *   **`\\'model_name\\': \\'gemini-2.5-flash\\'`**: Identifies the specific AI model that generated this content. \"Gemini 2.5 Flash\" is a fast and efficient version of Google\\'s Gemini model.\\n    *   **`\\'safety_ratings\\': []`**: This indicates that no safety issues (like harmful content) were detected in the generated response.\\n    *   **`\\'model_provider\\': \\'google_genai\\'`**: Specifies that the model was provided by Google\\'s Generative AI service.\\n\\n5.  **`id=\\'lc_run--019c41a8-9781-7661-ac0b-d8393bc63003-0\\'`**:\\n    *   This is a unique identifier for this specific \"run\" or generation request. It\\'s useful for logging, tracking, and debugging.\\n\\n6.  **`tool_calls=[]`**:\\n    *   This empty list indicates that the model did not make any calls to external tools (e.g., a search engine, a calculator, a code interpreter) during its generation process.\\n\\n7.  **`invalid_tool_calls=[]`**:\\n    *   This empty list confirms that there were no attempts to call tools that failed or were malformed.\\n\\n8.  **`usage_metadata={...}`**:\\n    *   This dictionary provides details about the token usage for this specific generation.\\n    *   **`\\'input_tokens\\': 6`**: The number of tokens in the prompt that was sent to the model to generate these jokes.\\n    *   **`\\'output_tokens\\': 1393`**: The number of tokens in the generated response (the jokes and their formatting).\\n    *   **`\\'total_tokens\\': 1399`**: The sum of input and output tokens.\\n    *   **`\\'input_token_details\\': {\\'cache_read\\': 0}`**: Technical detail about whether the input was served from a cache.\\n    *   **`\\'output_token_details\\': {\\'reasoning\\': 1299}`**: This is an interesting detail. It suggests that a significant portion of the output tokens were related to the model\\'s internal \"reasoning\" process to formulate the jokes, even if the final output is concise.\\n\\nIn summary, the provided text is a complete record of an AI model\\'s response to a prompt (which was likely something like \"tell me some cricket jokes\"), including the jokes themselves and all the technical details about how they were generated.'}\n"
     ]
    }
   ],
   "source": [
    "print(final_chain.invoke({\"topic\":\"cricket\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf45e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=final_chain.invoke({\"topic\":\"ai\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf52a4a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m())\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'content'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57b036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
